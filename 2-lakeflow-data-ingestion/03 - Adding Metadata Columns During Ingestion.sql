-- Databricks notebook source
-- MAGIC %md
-- MAGIC
-- MAGIC <div style="text-align: center; line-height: 0; padding-top: 9px;">
-- MAGIC   <img
-- MAGIC     src="https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png"
-- MAGIC     alt="Databricks Learning"
-- MAGIC   >
-- MAGIC </div>
-- MAGIC

-- COMMAND ----------

-- MAGIC %md
-- MAGIC # 3 - Adding Metadata Columns During Ingestion
-- MAGIC
-- MAGIC In this demonstration, we'll explore how to add metadata columns during data ingestion. 
-- MAGIC
-- MAGIC This process will include adding metadata, converting Unix timestamps to standard `DATE` format, and row  ingestion times.
-- MAGIC
-- MAGIC ### Learning Objectives
-- MAGIC
-- MAGIC By the end of this lesson, you should be able to:
-- MAGIC
-- MAGIC - Modify columns during data ingestion from cloud storage to your bronze table.
-- MAGIC - Add the current ingestion timestamp to the bronze.
-- MAGIC - Use the `_metadata` column to extract file-level metadata (e.g., file name, modification time) during ingestion.

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC ## Setup
-- MAGIC

-- COMMAND ----------

-- MAGIC %run ./_resources/00-setup $reset_all_data=true

-- COMMAND ----------

-- DBTITLE 1,View current catalog and schema
SELECT current_catalog(), current_schema()

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ## B. Explore the Data Source Files
-- MAGIC

-- COMMAND ----------

-- MAGIC %md
-- MAGIC 1. We'll create a table containing historical user data from Parquet files stored in the volume  
-- MAGIC    `'/Volumes/dbacademy_ecommerce/v01/raw/users-historical'` within Unity Catalog.
-- MAGIC
-- MAGIC    Use the `LIST` statement to view the files in this volume. Run the cell and review the results.
-- MAGIC
-- MAGIC    View the values in the **name** column that begin with **part-**. This shows that this volume contains multiple **Parquet** files.

-- COMMAND ----------

-- DBTITLE 1,List files in a raw data
LIST '/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/'

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ## C. Adding Metadata Columns to the Bronze Table During Ingestion
-- MAGIC
-- MAGIC When ingesting data into the Bronze layer, you can apply transformations during ingestion and also retrieve metadata about the input files using the **_metadata** column.
-- MAGIC
-- MAGIC The **_metadata** column is a hidden column available for all supported file formats. To include it in the returned data, you must explicitly select it in the read query that specifies the source.
-- MAGIC
-- MAGIC
-- MAGIC ### Ingestion Requirements
-- MAGIC
-- MAGIC During data ingestion, we'll perform the following actions:
-- MAGIC
-- MAGIC 1. Convert the parquet string datetime to a `timestamp` column.
-- MAGIC
-- MAGIC 2. Include the **input file name** to indicate the data raw source.
-- MAGIC
-- MAGIC 3. Include the **last modification** timestamp of the input file.
-- MAGIC
-- MAGIC 4. Add the **file ingestion time** to the Bronze table.
-- MAGIC
-- MAGIC **Note:** The `_metadata` column is available across all supported input file formats.
-- MAGIC  

-- COMMAND ----------

-- MAGIC %md
-- MAGIC 1. Run the cell below to display the parquet data in the `"/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/"` volume and view the results.
-- MAGIC
-- MAGIC     Notice that the **creation_date** column has a string.

-- COMMAND ----------

SELECT *
FROM read_files(
  '/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/',
  format => 'parquet')
LIMIT 10;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC ### C1. Convert the string datetime on Ingestion to Bronze.
-- MAGIC

-- COMMAND ----------

-- DBTITLE 1,Convert UNIX timestamp
SELECT
  *,
  to_timestamp(creation_date , 'MM-dd-yyyy HH:mm:ss') AS creation_date_converted
FROM read_files(
  "/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/",
  format => 'parquet')
LIMIT 10;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC
-- MAGIC ### C2. Adding Column Metadata on Ingestion
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC
-- MAGIC The following metadata can be added to the bronze table:
-- MAGIC
-- MAGIC - `_metadata.file_modification_time`: Adds the last modification time of the input file.
-- MAGIC
-- MAGIC - `_metadata.file_name`: Adds the input file name.
-- MAGIC
-- MAGIC - [`current_timestamp()`](https://docs.databricks.com/aws/en/sql/language-manual/functions/current_timestamp): Returns the current timestamp (`TIMESTAMP` data type) when the query starts, useful for tracking ingestion time.
-- MAGIC
-- MAGIC You can read more about the `_metadata` column in the [Databricks documentation](https://docs.databricks.com/en/ingestion/file-metadata-column.html). 

-- COMMAND ----------

-- MAGIC %md
-- MAGIC 1. Run the query below to add the following columns:
-- MAGIC
-- MAGIC    - **file_modification_time** and **file_name**, using the **_metadata** column to capture input file details.  
-- MAGIC    
-- MAGIC    - **ingestion_time**, which records the exact time the data was ingested.
-- MAGIC
-- MAGIC    Review the results. You should see the new columns **file_modification_time**, **source_file**, and **ingestion_time** added to the output.

-- COMMAND ----------

-- DBTITLE 1,Add metadata columns
SELECT
  *,
  to_timestamp(creation_date , 'MM-dd-yyyy HH:mm:ss') AS creation_date_converted,
  _metadata.file_modification_time AS file_modification_time,      -- Last data source file modification time
  _metadata.file_name AS source_file,                              -- Ingest data source file name
  current_timestamp() as ingestion_time                            -- Ingestion timestamp
FROM read_files(
  "/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/",
  format => 'parquet')
LIMIT 10;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ### C3. Creating the Final Bronze Table
-- MAGIC 1. Put it all together with the `CTAS` statement to create the Delta table.
-- MAGIC
-- MAGIC     Run the cell to create and view the new table **historical_users_bronze**.
-- MAGIC     
-- MAGIC     Confirm that the new columns **creation_date_converted**, **file_modification_time**, **source_file** and **ingestion_time** were created successfully in the bronze table.

-- COMMAND ----------

-- DBTITLE 1,Create the final bronze table
-- Drop the table if it exists for demonstration purposes
DROP TABLE IF EXISTS historical_users_bronze;


-- Create an empty table
CREATE TABLE historical_users_bronze AS
SELECT
  *,
  to_timestamp(creation_date , 'MM-dd-yyyy HH:mm:ss') AS creation_date_converted,
  _metadata.file_modification_time AS file_modification_time,      -- Last data source file modification time
  _metadata.file_name AS source_file,                              -- Ingest data source file name
  current_timestamp() as ingestion_time                            -- Ingestion timestamp
FROM read_files(
  "/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/",
  format => 'parquet');


-- View the final bronze table
SELECT * 
FROM historical_users_bronze
LIMIT 10;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ### C4. Exploring the Final Bronze Table

-- COMMAND ----------

-- MAGIC %md
-- MAGIC 1. With the additional metadata columns added to the bronze table, you can explore metadata information from the input files. For example, you can execute a query to see how many rows came from each Parquet file by querying the **source_file** column.

-- COMMAND ----------

-- DBTITLE 1,Count rows by parquet file
SELECT 
  source_file, 
  count(*) as total
FROM historical_users_bronze
GROUP BY source_file
ORDER BY source_file;

-- COMMAND ----------

-- MAGIC %md
-- MAGIC ## D. (BONUS) Python Equivalent

-- COMMAND ----------

-- MAGIC %python
-- MAGIC
-- MAGIC from pyspark.sql.functions import col, to_timestamp, current_timestamp
-- MAGIC from pyspark.sql.types import DateType
-- MAGIC
-- MAGIC # 1. Read parquet files in cloud storage into a Spark DataFrame
-- MAGIC df = (spark
-- MAGIC       .read
-- MAGIC       .format("parquet")
-- MAGIC       .load("/Volumes/main/dbdemos_data_ingestion/raw_data/user_parquet/")
-- MAGIC     )
-- MAGIC
-- MAGIC
-- MAGIC # 2. Add metadata columns
-- MAGIC df_with_metadata = (
-- MAGIC     df.withColumn("creation_date_converted", to_timestamp("creation_date", "MM-dd-yyyy HH:mm:ss"))
-- MAGIC       .withColumn("file_modification_time", col("_metadata.file_modification_time"))
-- MAGIC       .withColumn("source_file", col("_metadata.file_name"))
-- MAGIC       .withColumn("ingestion_time", current_timestamp())
-- MAGIC )
-- MAGIC
-- MAGIC
-- MAGIC # 3. Save as a Delta table
-- MAGIC (df_with_metadata
-- MAGIC  .write
-- MAGIC  .format("delta")
-- MAGIC  .mode("overwrite")
-- MAGIC  .saveAsTable("historical_users_bronze_python_metadata")
-- MAGIC )
-- MAGIC
-- MAGIC
-- MAGIC # 4. Read and display the table
-- MAGIC historical_users_bronze_python_metadata = spark.table("historical_users_bronze_python_metadata")
-- MAGIC
-- MAGIC display(historical_users_bronze_python_metadata)

-- COMMAND ----------

-- MAGIC %md
-- MAGIC &copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href="https://www.apache.org/" target="_blank">Apache Software Foundation</a>.<br/><br/><a href="https://databricks.com/privacy-policy" target="_blank">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use" target="_blank">Terms of Use</a> | <a href="https://help.databricks.com/" target="_blank">Support</a>
