{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "80d26bd0-79d4-4597-a855-80cb05bfc494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Delta Lake internals\n",
    "<img src=\"https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-logo-whitebackground.png\" style=\"width:200px; float: right\"/>\n",
    "\n",
    "Let's deep dive into Delta Lake internals.\n",
    "\n",
    "## Exploring delta structure\n",
    "\n",
    "Under the hood, Delta is composed of parquet files and a transactional log. Transactional log contains all the metadata operation. Databricks leverage this information to perform efficient data skipping at scale among other things.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=2940815195285158&notebook=%2F05-Advanced-Delta-Lake-Internal&demo_name=delta-lake&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdelta-lake%2F05-Advanced-Delta-Lake-Internal&version=1\">\n",
    "<!-- [metadata={\"description\":\"Quick introduction to Delta Lake. <br/><i>Use this content for quick Delta demo.</i>\",\n",
    " \"authors\":[\"quentin.ambard@databricks.com\"],\n",
    " \"db_resources\":{}}] -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21f6a9ec-2ca5-4591-aa69-38e34ba26b66",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Init the demo data"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ./_resources/00-setup $reset_all_data=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "331ff86e-b603-49da-bc1f-2f3a75d7e1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Exploring delta structure\n",
    "\n",
    "Delta is composed of parquet files and a transactional log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef56a3a-0d18-4d07-8ef1-2873671b560c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "spark.table('user_delta').write.mode('overwrite').save(f'/Volumes/{catalog}/{schema}/{volume_name}/user_delta_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e28227-f9d4-41a8-9d05-4730a9ec3afd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DESCRIBE DETAIL `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01710f2c-a7a7-44fc-9851-50b885a03c9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delta is composed of parquet files"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "delta_folder = spark.sql(f\"DESCRIBE DETAIL `delta`.`/Volumes/{catalog}/{schema}/{volume_name}/user_delta_table`\").collect()[0]['location']\n",
    "print(delta_folder)\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58e15825-7767-40d2-bd00-85748cc0f4b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "And a transactional log"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder+\"/_delta_log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "191a798f-2a95-4ff4-900f-76868d588866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "commit_log = dbutils.fs.head(delta_folder+\"/_delta_log/00000000000000000000.json\", 10000)\n",
    "print(json.dumps(json.loads(commit_log.split('\\n')[0]), indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f378bf34-b03a-4325-9c60-c922c8f6312e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unpacking the transaction log\n",
    "The transaction log is key to understanding Delta Lake because it is the common\n",
    "thread that runs through many of its most important features, including ACID transactions, scalable metadata handling, time travel and more. The Delta Lake transaction log is an ordered record of every transaction that has ever been performed on\n",
    "a Delta Lake table since its inception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eac180c-b2e1-456f-a67d-e1811d81b619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## OPTIMIZE in action\n",
    "Running an `OPTIMIZE` + `VACUUM` will re-order all our files.\n",
    "\n",
    "As you can see, we have multiple small parquet files in our folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d85b87e-aafd-49dc-840e-8b3177bbc5cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b89b1523-9aff-40a7-b907-aea4fb4a27aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's OPTIMIZE our table to see how the engine will compact the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3521738d-9f18-4064-9e1f-70ff503ea0f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "OPTIMIZE `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table`;\n",
    "-- as we vacuum with 0 hours, we need to remove the safety check:\n",
    "\n",
    "-- Note: commented out as this option isn't available on serverless compute for now - see ES-1302674\n",
    "-- set spark.databricks.delta.retentionDurationCheck.enabled = false;\n",
    "\n",
    "-- VACUUM `delta`.`/Volumes/main/dbdemos_delta_lake/delta_lake_raw_data/user_delta_table` retain 0 hours;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38a561c-9e72-451a-80ef-04310526e986",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Only one parquet file remains after the OPTIMIZE+VACUUM operation"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(delta_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a45c969b-c807-4d6c-8efc-16156ecf8de7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "That's it! You know everything about Delta Lake!\n",
    "\n",
    "As next step, you learn more about Spark Declarative Pipelines to simplify your ingestion pipeline: `dbdemos.install('pipeline-bike')`\n",
    "\n",
    "Go back to [00-Delta-Lake-Introduction]($./00-Delta-Lake-Introduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90fac0e9-f2cd-414a-973d-655b503d85d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05-Advanced-Delta-Lake-Internal",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
